"""
ä¸å¸¦æ€»ç»“çš„è½¬æ–‡å­—ç‰ˆæœ¬
"""
#å¿…é¡»ä½¿ç”¨å…¬ç½‘é“¾æ¥ï¼Œå¦åˆ™æ— æ³•è½¬å½•
import json
from http import HTTPStatus
import requests
from typing import List
import dashscope
import asyncio
from dashscope.audio.asr import Transcription
import os
from os import getenv
from dotenv import load_dotenv
load_dotenv()
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGSMITH_PROJECT"] = "imitate_v2t"
from  typing import Dict
from langsmith import traceable
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from link_parser.douyin_parse import parse_share_url
from link_parser.xhs_extract_links import extract_xhs_links
from link_parser.youtube_url_extract_single_url import youtube_extract_main
import pandas as pd
from datetime import datetime
from link_parser.BiliLink_main.quick_convert import quick_convert
load_dotenv()
dashscope.api_key = getenv("DASH_SCOPE_API_KEY")
sem = asyncio.Semaphore(5)

@traceable(name="v2t(1)bilibiliè§£æé“¾æ¥")
async def transform_bilibili_url(url:str)->str:
    bilibili_url = await quick_convert(url)
    return bilibili_url
#ä½¿ç”¨dashscopeçš„paraformer-v2æ¨¡å‹è¿›è¡Œè½¬å½•ï¼Œè¿”å›åŒ…å«æ‰€æœ‰å­ä»»åŠ¡çš„ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«æºæ–‡ä»¶urlå’Œè½¬å½•æ–‡å­—ç»“æœurl
@traceable(name="v2t(2)è½¬å½•æ–‡å­—")
async def get_one_text_url(url:str)->list:
    task_id = f"task_{id(url)}"  # ä¸ºæ¯ä¸ªä»»åŠ¡ç”Ÿæˆå”¯ä¸€ID
    print(f"[{task_id}] å¼€å§‹å¤„ç†è§†é¢‘: {url[:50]}...", flush=True)
    
    # âœ… ä¿®å¤ï¼šæ¯ä¸ªä»»åŠ¡ç‹¬ç«‹ä½¿ç”¨ä¿¡å·é‡ï¼Œå®ç°çœŸæ­£çš„å¹¶å‘æ§åˆ¶
    async with sem:  # æ§åˆ¶å•ä¸ªä»»åŠ¡çš„å¹¶å‘æ•°
        print(f"[{task_id}] è·å¾—ä¿¡å·é‡ï¼Œå¼€å§‹APIè°ƒç”¨", flush=True)
        transcribe_response = Transcription.async_call(
            model='paraformer-v2',
            file_urls=[url],
            language_hints=['zh', 'en']  # "language_hints"åªæ”¯æŒparaformer-v2æ¨¡å‹
        )

        while True:
            if transcribe_response.output.task_status == 'SUCCEEDED' or transcribe_response.output.task_status == 'FAILED':
                break
            transcribe_response = Transcription.fetch(task=transcribe_response.output.task_id)
            print(f"[{task_id}] è½¬å½•ä»»åŠ¡çŠ¶æ€: {transcribe_response.output.task_status}", flush=True)
            await asyncio.sleep(0.5)  # æ·»åŠ çŸ­æš‚ç­‰å¾…ï¼Œé¿å…è¿‡åº¦è½®è¯¢

        if transcribe_response.status_code == HTTPStatus.OK:
            results = transcribe_response.output["results"]
            print(f'[{task_id}] transcription done!')
            return results        #è¿”å›åŒ…å«æ‰€æœ‰å­ä»»åŠ¡çš„ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«æºæ–‡ä»¶urlå’Œè½¬å½•æ–‡å­—ç»“æœurl
        else:
            print(f"[{task_id}] è½¬å½•ä»»åŠ¡å¤±è´¥: {transcribe_response.output}", flush=True)
            return None

#æå–è½¬å½•æ–‡å­—ç»“æœJSON urlä¸­çš„æ–‡å­— - ä¿®å¤ä¸ºçœŸæ­£çš„å¼‚æ­¥å¹¶è¡Œ

async def get_text_url(url_list:list)->list:
    print(f"ğŸš€ å¼€å§‹å¼‚æ­¥å¹¶è¡Œå¤„ç†{len(url_list)}ä¸ªè§†é¢‘")
    
    # âœ… ä¿®å¤ï¼šç§»é™¤å¤–å±‚ä¿¡å·é‡ï¼Œè®©æ¯ä¸ªä»»åŠ¡è‡ªå·±ç®¡ç†å¹¶å‘
    tasks = [get_one_text_url(url) for url in url_list]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    all_text_url = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            print(f"âŒ ç¬¬{i+1}ä¸ªè§†é¢‘å¤„ç†å¤±è´¥: {result}")
        elif result is not None:
            all_text_url += result
            print(f"âœ… ç¬¬{i+1}ä¸ªè§†é¢‘å¤„ç†æˆåŠŸ")
        else:
            print(f"âš ï¸ ç¬¬{i+1}ä¸ªè§†é¢‘è¿”å›ç©ºç»“æœ")
    
    print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼Œå…±è·å¾—{len(all_text_url)}ä¸ªè½¬å½•ç»“æœ")
    return all_text_url

#æå–è½¬å½•æ–‡å­—ç»“æœurlä¸­çš„æ–‡å­—
@traceable(name="v2t(3)æå–è½¬å½•JSONæ ¼å¼ç»“æœurlä¸­çš„æ–‡å­—")
async def extract_text(transcrip_url)->Dict:
    timeout = 60
    try:
        response = requests.get(transcrip_url, timeout=timeout)
        response.raise_for_status()  # å¦‚æœä¸æ˜¯ 200ï¼Œä¼šæŠ›å¼‚å¸¸
        data =response.json()
        file_url=data["file_url"]
        text = data["transcripts"][0]["text"]
        result={"file_url":file_url,"text":text}
        print(f"æå–è½¬å½•æ–‡å­—ç»“æœurlä¸­çš„æ–‡å­—ï¼š\n{text}")
        return result         #è¿”å›åŒ…å«æºæ–‡ä»¶urlå’Œè½¬å½•æ–‡å­—ç»“æœçš„å­—å…¸
    except requests.exceptions.RequestException as e:
        print(f"è¯·æ±‚å‡ºé”™: {e}")
        return None 

@traceable(name="v2t(4)æ–‡æœ¬çº é”™")
async def correct_text(llm, text_dict:Dict):
    text = text_dict["text"]
    task_id = f"llm_{id(text)}"  # ä¸ºæ¯ä¸ªLLMä»»åŠ¡ç”Ÿæˆå”¯ä¸€ID
    print(f"[{task_id}] å¼€å§‹æ–‡æœ¬çº é”™ï¼Œæ–‡æœ¬é•¿åº¦: {len(text)}", flush=True)
    try:
        async with sem:  # æ§åˆ¶LLMè°ƒç”¨çš„å¹¶å‘æ•°
            print(f"[{task_id}] è·å¾—LLMä¿¡å·é‡ï¼Œå¼€å§‹çº é”™", flush=True)
            correct_prompt = ChatPromptTemplate.from_messages([
                ("system", """The following is a speech to text transcription of a video. 
                The text is primarily in Chinese, although it may also contain English. 
                Correct the transcription of any errors. Make sure to output the FULL transcript. 
                Output just the corrected transcript in your response and nothing else."""),
                ("user", """the following is the transcription of a video:\n
                -------------------------------------------------------------------
                {input}
                -------------------------------------------------------------------"""),
            ])
            correct_chain = correct_prompt | llm | StrOutputParser()
            corrected_text = await correct_chain.ainvoke({"input": text})
            print(f"[{task_id}] æ–‡æœ¬çº é”™å®Œæˆ\nåŸæ–‡æœ¬é•¿åº¦ï¼š{len(text)}\nçº é”™åæ–‡æœ¬é•¿åº¦ï¼š{len(corrected_text)}", flush=True)
            print(corrected_text)
            text_dict.update({"text":corrected_text})
            return text_dict
    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"[{task_id}] æ–‡æœ¬çº é”™å¤±è´¥è¿”å›åŸæ–‡æœ¬: {e}", flush=True)
        return text_dict      



async def v2t(llm,url_list:list)->List:
    print("å¼€å§‹è½¬å½•")
    results_list = await get_text_url(url_list)
    print(f"results_listï¼š{results_list}")
    print("æå–è½¬å½•æ–‡å­—ç»“æœurlä¸­çš„æ–‡å­—")
    
    # è¿‡æ»¤å‡ºæˆåŠŸçš„ç»“æœï¼Œå¹¶ç¡®ä¿æœ‰transcription_urlå­—æ®µ
    valid_results = []
    fail_list = []
    for result in results_list:
        if result["subtask_status"] == "SUCCEEDED" and result["transcription_url"] !="":
            valid_results.append(result)
        elif result["subtask_status"] == "FAILED":
            fail_list.append(result)
            print(f"è·³è¿‡å¤±è´¥æˆ–æ— æ•ˆçš„ç»“æœ: {result}")
    
    if not valid_results:
        print("æ²¡æœ‰æœ‰æ•ˆçš„è½¬å½•ç»“æœ")
        return []
    
    # æå–æ–‡æœ¬
    tasks = [extract_text(result["transcription_url"]) for result in valid_results]
    second_results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # è¿‡æ»¤å‡ºæˆåŠŸçš„æ–‡æœ¬æå–ç»“æœ
    second_result_list = []
    for _, result in enumerate(second_results):
        if isinstance(result, Exception):
            print(f"æ–‡æœ¬æå–å¤±è´¥: {result}")
        elif result is not None:
            second_result_list.append(result)
    
    if not second_result_list:
        print("æ²¡æœ‰æˆåŠŸæå–çš„æ–‡æœ¬")
        return []
    
    # æ–‡æœ¬çº é”™
    tasks = [correct_text(llm, result) for result in second_result_list]
    final_results = await asyncio.gather(*tasks, return_exceptions=True)
    
    final_result_list = []
    for result in final_results:
        if isinstance(result, Exception):
            print(f"æ–‡æœ¬çº é”™å¤±è´¥: {result}")
        elif result is not None:
            final_result_list.append(result)
    if len(fail_list) > 0:
        print(f"å¤±è´¥é“¾æ¥ï¼š{fail_list}")
    return final_result_list

async def _resolve_one_url(url: str) -> List[str]:
    """å°†åŸå§‹é“¾æ¥è§£ææˆå¯ç›´æ¥è½¬å½•çš„å…¬ç½‘ç›´é“¾ï¼ˆå¹¶å‘å‹å¥½ï¼Œä¸é˜»å¡äº‹ä»¶å¾ªç¯ï¼‰ã€‚"""
    try:
        # å·²ç»æ˜¯å…¬ç½‘ç›´é“¾ï¼Œç›´æ¥è¿”å›
        if url.startswith("https://finder.video.qq.com/") or url.startswith("http://wxapp.tc.qq.com/") or url.startswith("https://ppwtoss01.oss") or url.startswith("https://v5-small.douyinvod.com/"):
            return [url]

        # Bç«™ï¼šå¼‚æ­¥è½¬æ¢
        if ("https://www.bilibili.com/video/" in url) or ("https://b23.tv/" in url) or ("https://bili2233.cn/" in url):
            bilibili_url = await transform_bilibili_url(url)
            return [bilibili_url] if bilibili_url else []

        # æŠ–éŸ³ï¼šåŒæ­¥è§£æï¼Œæ”¾å…¥çº¿ç¨‹æ± é¿å…é˜»å¡
        if "douyin.com" in url:
            douyin_url = await asyncio.to_thread(parse_share_url, url)
            return [douyin_url] if douyin_url else []

        # å°çº¢ä¹¦ï¼šåŒæ­¥è§£æï¼Œæ”¾å…¥çº¿ç¨‹æ± é¿å…é˜»å¡
        if "xiaohongshu.com" in url or "xhslink.com" in url:
            xhs = await asyncio.to_thread(extract_xhs_links, url)
            if xhs and xhs.get("ok"):
                return list(xhs.get("download_urls") or [])
            print(f"å°çº¢ä¹¦é“¾æ¥è§£æå¤±è´¥: {xhs}")
            return []

        # YouTubeï¼šåŒæ­¥è§£æï¼Œæ”¾å…¥çº¿ç¨‹æ± é¿å…é˜»å¡
        if "youtube.com" in url or "youtu.be" in url:
            yt = await asyncio.to_thread(youtube_extract_main, url)
            if yt :
                return [yt]
            print(f"Youtubeé“¾æ¥è§£æå¤±è´¥: {yt}")
            return []

        # å…¶ä»–ï¼šç›´æ¥è¿”å›åŸURL
        return [url]
    except Exception as e:
        print(f"è§£æé“¾æ¥å‡ºé”™: {url} -> {e}")
        return []


async def _resolve_all_urls(url_list: List[str]) -> List[str]:
    print(f"ğŸ§­ å¹¶è¡Œè§£æ {len(url_list)} ä¸ªé“¾æ¥ä¸ºå¯è½¬å½•ç›´é“¾...")
    tasks = [_resolve_one_url(u) for u in url_list]
    groups = await asyncio.gather(*tasks, return_exceptions=True)
    direct_urls: List[str] = []
    for i, g in enumerate(groups):
        if isinstance(g, Exception):
            print(f"âŒ ç¬¬{i+1}ä¸ªé“¾æ¥è§£æå¼‚å¸¸: {g}")
            continue
        direct_urls.extend([x for x in g if isinstance(x, str) and x])
    print(f"âœ… è§£æå®Œæˆï¼Œè·å¾— {len(direct_urls)} æ¡ç›´é“¾")
    return direct_urls


async def main_v2t_no_summary(llm,url_list:list):
    # 1) å¹¶å‘è§£ææ¯ä¸ªé“¾æ¥ï¼ˆåˆ¤æ–­æ˜¯å¦å…¬ç½‘/éœ€è¦è§£æï¼‰ï¼Œç¡®ä¿ä¸é˜»å¡
    direct_url_list = await _resolve_all_urls(url_list)

    # 2) å¹¶å‘è¿›è¡Œè½¬å½•ã€æå–æ–‡æœ¬ä¸çº é”™ï¼ˆå„å­ä»»åŠ¡å†…éƒ¨å·²ä½¿ç”¨å¹¶å‘æ§åˆ¶ï¼‰
    if direct_url_list:
        direct_final_result_list = await v2t(llm, direct_url_list)
        print(f"å…¬ç½‘é“¾æ¥è½¬å½•ç»“æœï¼š{len(direct_final_result_list)}ä¸ªæˆåŠŸ")
    else:
        direct_final_result_list = []

    # 3) è¿”å›æœ€ç»ˆç»“æœ
    final_result_list = direct_final_result_list
    return final_result_list

def save_to_local(final_result_list:list):
    current_path = os.path.dirname(os.path.abspath(__file__))
    output_path = os.path.join(current_path,"result","v2t_result")   # è§†é¢‘é“¾æ¥è½¬æ–‡å­—ç»“æœä¿å­˜æ–‡ä»¶å¤¹è·¯å¾„
    if not os.path.exists(output_path):
        os.makedirs(output_path)
    file_list = []
    text_list = []
    for result in final_result_list:
        file_list.append(result["file_url"])
        text_list.append(result["text"])
    df = pd.DataFrame({"file_url":file_list,"text":text_list})
    time_now = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
    df.to_excel(os.path.join(output_path,f"v2t_result_{time_now}.xlsx"), index=False)

if __name__ == "__main__":
    correct_llm = ChatOpenAI(
    model="google/gemini-2.5-flash",
    max_tokens=64000,
    timeout=600,
    max_retries=2,
    api_key=getenv("OPENROUTER_API_KEY"),
    base_url=getenv("OPENROUTER_BASE_URL")
    )
    url_list = []
    while True:
        url = input("è¯·è¾“å…¥è§†é¢‘é“¾æ¥(è¾“å…¥å®Œæ¯•åå†æ¬¡å›è½¦å¼€å§‹æ‰§è¡Œè½¬æ–‡å­—):")
        if url == "":
            break
        url_list.append(url)
    # url_list = ["https://www.xiaohongshu.com/discovery/item/6895a4e3000000002501a26e?source=webshare&xhsshare=pc_web&xsec_token=ABgYkBkMvPzSYLMTYRRV2fwV5g3icoj6RmC3txDOTi70s=&xsec_source=pc_share",
    # "https://www.xiaohongshu.com/explore/684980030000000021007bb5?app_platform=ios&app_version=8.94.2&share_from_user_hidden=true&xsec_source=app_share&type=video&xsec_token=CBEjRSsYktwgn-4FmYmAXWlQcs_XHeDkZO0anJl1vGyEI=&author_share=1&xhsshare=WeixinSession&shareRedId=NztHODZISk08PkdFPz0zN0w5OTlKPjhK&apptime=1754356150&share_id=1dba6c6c1ec44a82a0b0217e5c8ff21c"]
    final_result_list = asyncio.run(main_v2t_no_summary(correct_llm,url_list))
    save_to_local(final_result_list)




